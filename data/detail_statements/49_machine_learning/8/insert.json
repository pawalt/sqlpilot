[
  {
    "statements": [
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (1, 'Model 1', 'Layer 1, Layer 2', 'Adam', 'MSE')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (2, 'Model 2', 'Layer 1, Layer 2, Layer 3', 'SGD', 'Cross Entropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (3, 'Model 3', 'Layer 1', 'RMSprop', 'Huber Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (4, 'Model 4', 'Layer 1, Layer 2, Layer 3', 'Adam', 'Binary Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (5, 'Model 5', 'Layer 1', 'SGD', 'Categorical Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (6, 'Model 6', 'Layer 1, Layer 2', 'Adagrad', 'MSE')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (7, 'Model 7', 'Layer 1', 'Adam', 'Huber Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (8, 'Model 8', 'Layer 1, Layer 2, Layer 3', 'SGD', 'Binary Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (9, 'Model 9', 'Layer 1, Layer 2', 'RMSprop', 'Categorical Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (10, 'Model 10', 'Layer 1, Layer 2', 'Adam', 'MSE')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (11, 'Model 11', 'Layer 1, Layer 2, Layer 3', 'SGD', 'Cross Entropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (12, 'Model 12', 'Layer 1', 'RMSprop', 'Huber Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (13, 'Model 13', 'Layer 1, Layer 2, Layer 3', 'Adam', 'Binary Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (14, 'Model 14', 'Layer 1', 'SGD', 'Categorical Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (15, 'Model 15', 'Layer 1, Layer 2', 'Adagrad', 'MSE')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (16, 'Model 16', 'Layer 1', 'Adam', 'Huber Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (17, 'Model 17', 'Layer 1, Layer 2, Layer 3', 'SGD', 'Binary Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (18, 'Model 18', 'Layer 1, Layer 2', 'RMSprop', 'Categorical Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (19, 'Model 19', 'Layer 1, Layer 2', 'Adam', 'MSE')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (20, 'Model 20', 'Layer 1, Layer 2, Layer 3', 'SGD', 'Cross Entropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (1, 'Model 1', 'CNN, LSTM, Dense', 'Adam', 'Mean Squared Error')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (2, 'Model 2', 'CNN, Dense', 'SGD', 'Cross Entropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (3, 'Model 3', 'LSTM, Dense', 'RMSprop', 'Binary Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (4, 'Model 4', 'CNN, LSTM', 'Adagrad', 'Categorical Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (5, 'Model 5', 'LSTM, Dense, CNN', 'Adam', 'Mean Absolute Error')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (6, 'Model 6', 'Dense, CNN', 'SGD', 'Huber Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (7, 'Model 7', 'CNN', 'RMSprop', 'Log Cosh Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (8, 'Model 8', 'CNN, LSTM, Dense', 'Adagrad', 'Poisson Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (9, 'Model 9', 'Dense', 'Adam', 'Kullback-Leibler Divergence')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (10, 'Model 10', 'LSTM, Dense', 'SGD', 'Hinge Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (11, 'Model 11', 'CNN, LSTM', 'RMSprop', 'Squared Hinge Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (12, 'Model 12', 'CNN, Dense, LSTM', 'Adagrad', 'Categorical Hinge Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (13, 'Model 13', 'LSTM', 'Adam', 'Poisson Hinge Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (14, 'Model 14', 'Dense, CNN', 'SGD', 'Log Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (15, 'Model 15', 'CNN', 'RMSprop', 'Exponential Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (16, 'Model 16', 'CNN, LSTM, Dense', 'Adagrad', 'Softmax Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (17, 'Model 17', 'Dense', 'Adam', 'Sigmoid Crossentropy')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (18, 'Model 18', 'Dense, LSTM', 'SGD', 'Binary Hinge Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (19, 'Model 19', 'CNN, LSTM, Dense', 'RMSprop', 'Multiclass Hinge Loss')",
      "INSERT INTO DeepLearningModel (model_id, model_name, layers, optimizer, loss_function) VALUES (20, 'Model 20', 'LSTM, CNN', 'Adagrad', 'Weighted Crossentropy')"
    ]
  },
  {
    "statements": [
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (1, 'MNIST', 'Handwritten digits dataset', 60000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (2, 'CIFAR-10', 'Image dataset with 10 classes', 60000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (3, 'COCO', 'Common Objects in COntext dataset', 118287);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (4, 'IMDB', 'Movie reviews dataset', 50000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (5, 'Fashion-MNIST', 'Fashion images dataset', 60000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (6, 'SVHN', 'Street View House Numbers dataset', 73257);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (7, 'CelebA', 'Large-scale CelebFaces Attributes dataset', 202599);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (8, 'Cityscapes', 'Semantic urban scene understanding dataset', 5000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (9, 'VGGFace', 'VGGFace dataset for face recognition', 5000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (10, 'Pascal VOC', 'Visual Object Classes dataset for object recognition', 17125);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (11, 'Open Images', 'Open Images Dataset V4 for object detection', 5750033);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (12, 'Caltech-256', 'Caltech-256 benchmark dataset', 30607);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (13, 'Kitti', 'KITTI Vision Benchmark Suite', 7481);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (14, 'UCI ML Repository', 'UCI Machine Learning Repository dataset', 417);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (15, 'Stanford Cars', 'Stanford Cars Dataset', 16185);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (16, 'UCMerced Land Use', 'Land Use Dataset from UCMerced', 2100);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (17, 'Oxford Flowers', 'Oxford Flowers 102 dataset', 8189);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (18, 'AT&T Faces', 'AT&T Faces dataset for face recognition', 400);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (19, 'Kaggle Cats vs Dogs', 'Kaggle dataset for cat vs dog image classification', 25000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (20, 'MIT-BIH Arrhythmia', 'ECG data for arrhythmia detection', 11249);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (1, 'MNIST', 'Handwritten digits dataset', 60000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (2, 'CIFAR-10', '10 class object recognition dataset', 50000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (3, 'IMDB Reviews', 'Large movie review sentiment analysis dataset', 100000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (4, 'Flickr30k', 'Image captioning dataset with 30k images', 30000);",
      "INSERT INTO deep_learning_datasets (id, dataset_name, dataset_description, dataset_size) VALUES (5, 'Yelp Reviews', 'Business reviews dataset', 200000);",
      "INSERT INTO model_training_results (result_id, dataset_id, model_name, training_accuracy, validation_accuracy) VALUES (1, 1, 'CNN', 0.85, 0.82);",
      "INSERT INTO model_training_results (result_id, dataset_id, model_name, training_accuracy, validation_accuracy) VALUES (2, 2, 'ResNet', 0.78, 0.75);",
      "INSERT INTO model_training_results (result_id, dataset_id, model_name, training_accuracy, validation_accuracy) VALUES (3, 3, 'LSTM', 0.90, 0.88);",
      "INSERT INTO model_training_results (result_id, dataset_id, model_name, training_accuracy, validation_accuracy) VALUES (4, 4, 'GPT-3', 0.92, 0.89);",
      "INSERT INTO model_training_results (result_id, dataset_id, model_name, training_accuracy, validation_accuracy) VALUES (5, 5, 'BERT', 0.87, 0.84);"
    ]
  },
  {
    "statements": [
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Image Classification', 1000, '2022-10-01 08:00:00')",
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Object Detection', 2000, '2022-10-02 10:30:00')",
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Natural Language Processing', 1500, '2022-10-03 12:45:00')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (1, 'cat')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (1, 'dog')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (2, 'car')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (2, 'person')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (3, 'text')",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('CNN', 1, 0.85, 0.1)",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('RCNN', 2, 0.78, 0.15)",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('Bert', 3, 0.92, 0.05)",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('LSTM', 1, 0.88, 0.12)",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('YOLO', 2, 0.79, 0.11)",
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Speech Recognition', 1200, '2022-10-04 14:30:00')",
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Sentiment Analysis', 1800, '2022-10-05 16:15:00')",
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Stock Price Prediction', 800, '2022-10-06 18:45:00')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (4, 'audio')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (5, 'emotion')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (6, 'stock')",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('GRU', 4, 0.75, 0.2)",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('Transformer', 5, 0.86, 0.08)",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('LSTM', 6, 0.83, 0.1)",
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Image Classification', 1000, '2022-01-15 12:00:00')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (1, 'Cat')",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('CNN Model', 1, 0.85, 0.1)",
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Natural Language Processing', 500, '2022-01-16 09:30:00')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (2, 'Sentiment Analysis')",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('RNN Model', 2, 0.78, 0.2)",
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Object Detection', 800, '2022-01-17 14:45:00')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (3, 'Persons')",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('YOLO Model', 3, 0.92, 0.05)",
      "INSERT INTO deep_learning_datasets (dataset_name, dataset_size, last_updated) VALUES ('Anomaly Detection', 300, '2022-01-18 11:20:00')",
      "INSERT INTO data_labels (dataset_id, label_name) VALUES (4, 'Fraudulent Transactions')",
      "INSERT INTO model_results (model_name, dataset_id, accuracy, loss) VALUES ('Isolation Forest', 4, 0.95, 0.02)"
    ]
  },
  {
    "statements": [
      "INSERT INTO dataset (id, dataset_name, description) VALUES (1, 'Dataset1', 'This is dataset 1'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (2, 'Dataset2', 'This is dataset 2'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (3, 'Dataset3', 'This is dataset 3'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (4, 'Dataset4', 'This is dataset 4'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (5, 'Dataset5', 'This is dataset 5'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (6, 'Dataset6', 'This is dataset 6'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (7, 'Dataset7', 'This is dataset 7'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (8, 'Dataset8', 'This is dataset 8'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (9, 'Dataset9', 'This is dataset 9'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (10, 'Dataset10', 'This is dataset 10'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (11, 'Dataset11', 'This is dataset 11'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (12, 'Dataset12', 'This is dataset 12'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (13, 'Dataset13', 'This is dataset 13'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (14, 'Dataset14', 'This is dataset 14'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (15, 'Dataset15', 'This is dataset 15'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (16, 'Dataset16', 'This is dataset 16'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (17, 'Dataset17', 'This is dataset 17'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (18, 'Dataset18', 'This is dataset 18'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (19, 'Dataset19', 'This is dataset 19'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (20, 'Dataset20', 'This is dataset 20'); ",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (1, 'Dataset A', 'This is dataset A description');",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (2, 'Dataset B', 'This is dataset B description');",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (3, 'Dataset C', 'This is dataset C description');",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (4, 'Dataset D', 'This is dataset D description');",
      "INSERT INTO dataset (id, dataset_name, description) VALUES (5, 'Dataset E', 'This is dataset E description');",
      "INSERT INTO model (model_id, model_name, algorithm, accuracy) VALUES (1, 'Model 1', 'Algorithm A', 0.85);",
      "INSERT INTO model (model_id, model_name, algorithm, accuracy) VALUES (2, 'Model 2', 'Algorithm B', 0.92);",
      "INSERT INTO model (model_id, model_name, algorithm, accuracy) VALUES (3, 'Model 3', 'Algorithm C', 0.78);",
      "INSERT INTO model (model_id, model_name, algorithm, accuracy) VALUES (4, 'Model 4', 'Algorithm D', 0.91);",
      "INSERT INTO model (model_id, model_name, algorithm, accuracy) VALUES (5, 'Model 5', 'Algorithm E', 0.88);",
      "INSERT INTO training_metric (metric_id, model_id, loss, accuracy) VALUES (1, 1, 0.15, 0.85);",
      "INSERT INTO training_metric (metric_id, model_id, loss, accuracy) VALUES (2, 2, 0.08, 0.92);",
      "INSERT INTO training_metric (metric_id, model_id, loss, accuracy) VALUES (3, 3, 0.22, 0.78);",
      "INSERT INTO training_metric (metric_id, model_id, loss, accuracy) VALUES (4, 4, 0.09, 0.91);",
      "INSERT INTO training_metric (metric_id, model_id, loss, accuracy) VALUES (5, 5, 0.12, 0.88);",
      "INSERT INTO prediction (prediction_id, model_id, input_data, output_data, prediction_label) VALUES (1, 1, 'Input 1', 'Output 1', 'Label A');",
      "INSERT INTO prediction (prediction_id, model_id, input_data, output_data, prediction_label) VALUES (2, 2, 'Input 2', 'Output 2', 'Label B');",
      "INSERT INTO prediction (prediction_id, model_id, input_data, output_data, prediction_label) VALUES (3, 3, 'Input 3', 'Output 3', 'Label C');",
      "INSERT INTO prediction (prediction_id, model_id, input_data, output_data, prediction_label) VALUES (4, 4, 'Input 4', 'Output 4', 'Label D');",
      "INSERT INTO prediction (prediction_id, model_id, input_data, output_data, prediction_label) VALUES (5, 5, 'Input 5', 'Output 5', 'Label E');"
    ]
  },
  {
    "statements": [
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (1, 'blob_data_1', '2022-10-01 10:00:00');",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (2, 'blob_data_2', '2022-10-02 11:15:00');",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (3, 'blob_data_3', '2022-10-03 12:30:00');",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (4, 'blob_data_4', '2022-10-04 13:45:00');",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (5, 'blob_data_5', '2022-10-05 14:00:00');",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (6, 'blob_data_6', '2022-10-06 15:15:00');",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (7, 'blob_data_7', '2022-10-07 16:30:00');",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (8, 'blob_data_8', '2022-10-08 17:45:00');",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (9, 'blob_data_9', '2022-10-09 18:00:00');",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (10, 'blob_data_10', '2022-10-10 19:15:00');",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (1, '{\"layers\": [16, 32, 64]}', 1);",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (2, '{\"layers\": [32, 64, 128]}', 2);",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (3, '{\"layers\": [64, 128, 256]}', 3);",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (4, '{\"layers\": [128, 256, 512]}', 4);",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (5, '{\"layers\": [256, 512, 1024]}', 5);",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (6, '{\"layers\": [512, 1024, 2048]}', 6);",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (7, '{\"layers\": [1024, 2048, 4096]}', 7);",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (8, '{\"layers\": [2048, 4096, 8192]}', 8);",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (9, '{\"layers\": [4096, 8192, 16384]}', 9);",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (10, '{\"layers\": [8192, 16384, 32768]}', 10);",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (1, 'Some BLOB Data', '2022-01-01 12:00:00')",
      "INSERT INTO deep_learning_data (id, data, created_at) VALUES (2, 'More BLOB Data', '2022-01-02 09:30:00')",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (1, '{\"layers\": [\"input\", \"hidden\", \"output\"]}', 1)",
      "INSERT INTO neural_networks (network_id, structure, training_data_id) VALUES (2, '{\"layers\": [\"input\", \"hidden1\", \"hidden2\", \"output\"]}', 2)",
      "INSERT INTO model_results (result_id, model_id, result) VALUES (1, 1, '{\"accuracy\": 0.85, \"loss\": 0.12}')",
      "INSERT INTO model_results (result_id, model_id, result) VALUES (2, 2, '{\"accuracy\": 0.78, \"loss\": 0.15}')",
      "INSERT INTO training_logs (log_id, model_id, log_info) VALUES (1, 1, 'Training model with new dataset')",
      "INSERT INTO training_logs (log_id, model_id, log_info) VALUES (2, 2, 'Fine-tuning model with additional data')",
      "INSERT INTO hyperparameters (hyper_id, model_id, params) VALUES (1, 1, '{\"learning_rate\": 0.001, \"epochs\": 100}')",
      "INSERT INTO hyperparameters (hyper_id, model_id, params) VALUES (2, 2, '{\"learning_rate\": 0.01, \"epochs\": 50}')"
    ]
  }
]