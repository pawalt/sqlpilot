[
  {
    "statements": [
      "INSERT INTO data_pipeline (id, source_id, source_name, data_type, timestamp, transformed_data, loaded_flag) VALUES (1, 101, 'Source A', 'Type A', '2021-10-15 12:30:00', 'Transformed Data A', TRUE);",
      "INSERT INTO data_pipeline (source_name, source_id, timestamp, data_type, transformed_data, id, loaded_flag) VALUES ('Source B', 102, '2021-10-16 14:45:00', 'Type B', 'Transformed Data B', 2, FALSE);",
      "INSERT INTO data_pipeline (loaded_flag, id, source_name, timestamp, data_type, source_id, transformed_data) VALUES (TRUE, 3, 'Source C', '2021-10-17 10:15:00', 'Type C', 103, 'Transformed Data C');",
      "INSERT INTO data_pipeline (id, transformed_data, data_type, loaded_flag, timestamp, source_name, source_id) VALUES (4, 'Transformed Data D', 'Type D', FALSE, '2021-10-18 08:30:00', 'Source D', 104);",
      "INSERT INTO data_pipeline SET id=5, source_id=105, source_name='Source E', data_type='Type E', timestamp='2021-10-19 09:45:00', transformed_data='Transformed Data E', loaded_flag=TRUE;",
      "INSERT INTO data_pipeline (id, source_id, source_name, data_type, timestamp, transformed_data, loaded_flag) VALUES (1, 101, 'Source A', 'Type X', '2022-12-31 23:59:59', 'Transformed Data A', false);",
      "INSERT INTO data_pipeline (id, source_name, timestamp, loaded_flag, source_id, data_type, transformed_data) VALUES (2, 'Source B', '2023-01-01 00:00:00', true, 102, 'Type Y', 'Transformed Data B');",
      "INSERT INTO data_pipeline (source_name, id, timestamp, loaded_flag, transformed_data, data_type, source_id) VALUES ('Source C', 3, '2023-01-02 12:00:00', false, 'Transformed Data C', 'Type Z', 103);",
      "INSERT INTO data_pipeline (source_id, transformed_data, source_name, id, timestamp, loaded_flag, data_type) VALUES (104, 'Transformed Data D', 'Source D', 4, '2023-01-03 08:00:00', true, 'Type X');",
      "INSERT INTO data_pipeline (source_id, timestamp, loaded_flag, transformed_data, data_type, source_name, id) VALUES (105, '2023-01-04 15:30:00', false, 'Transformed Data E', 'Type Y', 'Source E', 5);"
    ]
  },
  {
    "statements": [
      "INSERT INTO pipelines (id, source, destination, etl_process) VALUES (1, 'Source A', 'Destination A', 'ETL Process A');",
      "INSERT INTO pipelines (source, destination, id, etl_process) VALUES ('Source B', 'Destination B', 2, 'ETL Process B');",
      "INSERT INTO pipelines VALUES (3, 'Source C', 'Destination C', 'ETL Process C');",
      "INSERT INTO pipelines (id, source, destination) VALUES (4, 'Source D', 'Destination D');",
      "INSERT INTO pipelines (etl_process, destination, id, source) VALUES ('ETL Process E', 'Destination E', 5, 'Source E');",
      "INSERT INTO data_sources (id, source_name, source_type, source_connection) VALUES (1, 'Sales Data', 'csv', 'sales.csv');",
      "INSERT INTO pipelines (source, destination, etl_process, id) VALUES ('Data Warehouse', 'Data Lake', 'ETL', 1);",
      "INSERT INTO pipelines (id, source, destination, etl_process) VALUES (2, 'API', 'Database', 'Data Extraction');",
      "INSERT INTO data_sources (source_type, source_name, id, source_connection) VALUES ('API', 'Customer Data', 2, 'api_key=12345');",
      "INSERT INTO data_sources (source_name, source_type, source_connection, id) VALUES ('Support Data', 'database', 'host=localhost;user=admin;password=1234', 3);"
    ]
  },
  {
    "statements": [
      "INSERT INTO data_sources (id, source_name, connection_details) VALUES (1, 'Source A', '{\"host\": \"example.com\", \"user\": \"user1\"}');",
      "INSERT INTO data_transformations (transformation_name, transformation_script, id) VALUES ('Transformation 1', 'SELECT * FROM table1;', 1);",
      "INSERT INTO data_load (load_name, load_query, id) VALUES ('Load 1', 'INSERT INTO table2 (col1, col2) VALUES (1, 'value');', 1);",
      "INSERT INTO data_sources (id, source_name, connection_details) VALUES (2, 'Source B', '{\"host\": \"example.org\", \"user\": \"user2\"}');",
      "INSERT INTO data_transformations (transformation_name, transformation_script, id) VALUES ('Transformation 2', 'SELECT col1, col2 FROM table1;', 2);",
      "INSERT INTO data_sources (id, source_name, connection_details) VALUES (1, 'Source A', '{\"host\": \"localhost\", \"port\": 5432, \"database\": \"db1\"}');",
      "INSERT INTO data_load (id, load_name, load_query) VALUES (2, 'Load X', 'SELECT * FROM tableA;');",
      "INSERT INTO data_load (id, load_name, load_query) VALUES (3, 'Load Y', 'SELECT column1, column2 FROM tableB WHERE condition = 1;');",
      "INSERT INTO data_transformations (id, transformation_name, transformation_script) VALUES (4, 'Transformation 1', 'UPDATE tableC SET column3 = column3 + 1;');",
      "INSERT INTO data_sources (id, source_name, connection_details) VALUES (5, 'Source B', '{\"host\": \"example.com\", \"port\": 3306, \"database\": \"db2\"}');"
    ]
  },
  {
    "statements": [
      "INSERT INTO ETL_Stage (id, source, data, created_at) VALUES (1, 'source1', {'key1': 'value1'}, '2022-01-01 12:00:00')",
      "INSERT INTO Data_Extract (id, source, extract_date, data) VALUES (2, 'source2', '2022-01-02', {'key2': 'value2'})",
      "INSERT INTO Data_Transform (id, source, transform_date, transformed_data) VALUES (3, 'source3', '2022-01-03', {'key3': 'value3'})",
      "INSERT INTO Data_Load (id, destination, load_date, loaded_data) VALUES (4, 'destination1', '2022-01-04', {'key4': 'value4'})",
      "INSERT INTO Data_Load (id, destination, load_date, loaded_data) VALUES (5, 'destination2', '2022-01-05', {'key5': 'value5'})",
      "INSERT INTO ETL_Stage (id, source, data, created_at) VALUES (1, 'source1', '{\"key\": \"value1\"}', '2022-01-01 08:00:00')",
      "INSERT INTO Data_Extract (id, source, extract_date, data) VALUES (2, 'source2', '2022-01-02', '{\"key\": \"value2\"}')",
      "INSERT INTO Data_Transform (id, source, transform_date, transformed_data) VALUES (3, 'source3', '2022-01-03', '{\"key\": \"value3\"}')",
      "INSERT INTO Data_Load (id, destination, load_date, loaded_data) VALUES (4, 'destination1', '2022-01-04', '{\"key\": \"value4\"}')",
      "INSERT INTO Data_Extract (id, source, extract_date, data) VALUES (5, 'source5', '2022-01-05', '{\"key\": \"value5\"}')"
    ]
  },
  {
    "statements": [
      "INSERT INTO source_data_table (id, source_name, data_type, data_value) VALUES (1, 'Source A', 'Type1', 10.5);",
      "INSERT INTO transform_data_table (id, transformed_data) VALUES (1, '{\"key\": \"value\"}');",
      "INSERT INTO load_data_table (load_status, loaded_data, id) VALUES ('Success', '{\"key1\": 100, \"key2\": 200}', 1);",
      "INSERT INTO pipeline_logs_table (log_message, timestamp, id) VALUES ('Pipeline started', '2022-01-05 12:00:00', 1);",
      "INSERT INTO pipeline_metadata_table (transform_table_name, pipeline_name, load_table_name, id, source_table_name) VALUES ('transform_table', 'Pipeline1', 'load_table', 1, 'source_table');",
      "INSERT INTO source_data_table (id, source_name, data_type, data_value) VALUES (1, 'Source A', 'Type A', 10.5);",
      "INSERT INTO transform_data_table (id, transformed_data) VALUES (1, '{\"key\": \"value\"}');",
      "INSERT INTO load_data_table (id, loaded_data, load_status) VALUES (1, '{\"key\": \"value\"}', 'Successful');",
      "INSERT INTO pipeline_logs_table (id, timestamp, log_message) VALUES (1, '2022-10-15 08:30:00', 'Pipeline executed successfully.');",
      "INSERT INTO pipeline_metadata_table (id, pipeline_name, source_table_name, transform_table_name, load_table_name) VALUES (1, 'ETL Pipeline 1', 'source_data_table', 'transform_data_table', 'load_data_table');"
    ]
  }
]