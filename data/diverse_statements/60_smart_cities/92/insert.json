[
  {
    "statements": [
      "INSERT INTO NLP_tasks (task_id, task_name, task_description, task_status, created_at) VALUES (1, 'Read research papers', 'Read 3 research papers related to NLP', 'open', '2022-03-15 10:00:00')",
      "INSERT INTO NLP_tasks (task_status, task_description, task_name, task_id, created_at) VALUES ('completed', 'Write a summary of the research papers', 'Summarize research papers', 2, '2022-03-16 15:30:00')",
      "INSERT INTO NLP_tasks VALUES (3, 'Implement NLP model', 'Implement a basic NLP model using Python', 'in progress', '2022-03-17 09:00:00')",
      "INSERT INTO NLP_tasks (task_id, task_status, created_at, task_name, task_description) VALUES (4, 'open', '2022-03-18 12:00:00', 'Attend NLP workshop', 'Attend a virtual workshop on NLP techniques')",
      "INSERT INTO NLP_tasks (task_status, task_id, created_at, task_name, task_description) VALUES ('open', 5, '2022-03-19 08:30:00', 'Practice NLP algorithms', 'Solve NLP algorithm problems to improve skills')",
      "INSERT INTO NLP_tasks (task_id, task_name, task_description, task_status, created_at) VALUES (1, 'Data Cleaning', 'Clean and preprocess the dataset before analysis', 'completed', NOW());",
      "INSERT INTO NLP_tasks (task_id, task_name, task_description, task_status, created_at) VALUES (2, 'Text Classification', 'Develop a model to classify text data', 'in progress', NOW());",
      "INSERT INTO NLP_tasks (task_id, task_name, task_description, task_status, created_at) VALUES (3, 'Named Entity Recognition', 'Implement NER to extract entities from text', 'open', NOW());",
      "INSERT INTO NLP_tasks (task_id, task_name, task_description, task_status, created_at) VALUES (4, 'Sentiment Analysis', 'Analyze sentiment of text data using machine learning', 'in progress', NOW());",
      "INSERT INTO NLP_tasks (task_id, task_name, task_description, task_status, created_at) VALUES (5, 'Topic Modeling', 'Apply LDA to identify topics in text corpus', 'open', NOW());"
    ]
  },
  {
    "statements": [
      "INSERT INTO nlp_tasks (task_id, task_name, task_description) VALUES (1, 'Document Classification', 'Classify documents based on their content.');",
      "INSERT INTO nlp_tasks (task_description, task_name, task_id) VALUES ('Extractive Summarization', 'Summarize a document by selecting important sentences.', 2);",
      "INSERT INTO nlp_results (result_id, task_id, result_data, result_timestamp) VALUES (1, 1, '{\"category\": \"important\", \"accuracy\": 0.85}', '2022-01-15 08:30:00');",
      "INSERT INTO nlp_results (result_timestamp, result_data, task_id, result_id) VALUES ('2022-01-20 12:45:00', '{\"sentiment\": \"positive\", \"keywords\": [\"exciting\", \"informative\"]}', 2, 2);",
      "INSERT INTO nlp_results (task_id, result_timestamp, result_data, result_id) VALUES (1, '2022-01-25 16:00:00', '{\"sentiment\": \"negative\", \"keywords\": [\"error\", \"issue\"]}', 3);",
      "INSERT INTO nlp_tasks (task_id, task_name, task_description) VALUES (1, 'Named Entity Recognition', 'Identifying named entities in text data.');",
      "INSERT INTO nlp_results (result_id, task_id, result_data, result_timestamp) VALUES (1, 1, '{\"entities\": [\"Apple\", \"Google\", \"Microsoft\"]}', '2022-01-15 08:00:00');",
      "INSERT INTO nlp_tasks (task_id, task_name, task_description) VALUES (2, 'Sentiment Analysis', 'Determine the sentiment of text data.');",
      "INSERT INTO nlp_results (result_id, task_id, result_data, result_timestamp) VALUES (2, 2, '{\"sentiment\": \"positive\"}', '2022-01-16 09:30:00');",
      "INSERT INTO nlp_tasks (task_id, task_name, task_description) VALUES (3, 'Text Classification', 'Classify text into categories.');"
    ]
  },
  {
    "statements": [
      "INSERT INTO NLP_Documents (document_id, document_text) VALUES ('3bf3d6e2-7de8-4b0d-81f2-d2e6f0e47829', 'This is document 1');",
      "INSERT INTO NLP_Tokens (token_id, token_text, document_id) VALUES ('1e9d9a06-09ba-4fd2-91e7-118bbddabe19', 'token1', '3bf3d6e2-7de8-4b0d-81f2-d2e6f0e47829');",
      "INSERT INTO NLP_Annotations (annotation_id, annotation_type, start_offset, end_offset, token_id) VALUES ('8422e7c5-292b-4109-968f-9d111d3eb645', 'POS', 0, 4, '1e9d9a06-09ba-4fd2-91e7-118bbddabe19');",
      "INSERT INTO NLP_Documents (document_id, document_text) VALUES ('c66b0d37-183c-4956-a0b8-1ed72b4685b7', 'This is document 2');",
      "INSERT INTO NLP_Tokens (token_id, token_text, document_id) VALUES ('4abfb3a8-712a-449c-9edc-44f9826781d3', 'token2', 'c66b0d37-183c-4956-a0b8-1ed72b4685b7');",
      "INSERT INTO NLP_Documents (document_id, document_text) VALUES ('5a013e9b-19c7-4350-a8ba-49a51ef82ca8', 'This is the first document.');",
      "INSERT INTO NLP_Tokens (token_id, token_text, document_id) VALUES ('98f2b490-7ed2-4e5f-8f7d-3e5ccff14292', 'token1', '5a013e9b-19c7-4350-a8ba-49a51ef82ca8');",
      "INSERT INTO NLP_Annotations (annotation_id, annotation_type, start_offset, end_offset, token_id) VALUES ('bb8f12f0-bc67-4e43-a241-50fb9dd671b1', 'entity', 2, 6, '98f2b490-7ed2-4e5f-8f7d-3e5ccff14292');",
      "INSERT INTO NLP_Tokens (token_id, token_text, document_id) VALUES ('0f91f90b-4e4f-41be-bd0d-3f9e2c3ec27e', 'token2', '5a013e9b-19c7-4350-a8ba-49a51ef82ca8');",
      "INSERT INTO NLP_Annotations (annotation_id, annotation_type, start_offset, end_offset, token_id) VALUES ('09ec6c86-15f8-4b1e-9e51-e14ec7f58dcf', 'phrase', 7, 13, '0f91f90b-4e4f-41be-bd0d-3f9e2c3ec27e');"
    ]
  },
  {
    "statements": [
      "INSERT INTO NLP_Documents (document_id, document_text) VALUES (1, 'This is document 1');",
      "INSERT INTO NLP_Keywords (keyword_id, keyword_text) VALUES (1, 'keyword1');",
      "INSERT INTO NLP_Entities (entity_id, entity_text, entity_type) VALUES (1, 'entity1', 'type1');",
      "INSERT INTO NLP_Annotations (annotation_id, document_id, keyword_id, entity_id) VALUES (1, 1, 1, 1);",
      "INSERT INTO NLP_Annotations (annotation_id, document_id, keyword_id, entity_id) VALUES (2, 1, 1, 1);",
      "INSERT INTO NLP_Documents (document_id, document_text) VALUES (1, 'This is document 1');",
      "INSERT INTO NLP_Keywords (keyword_id, keyword_text) VALUES (1, 'keyword1');",
      "INSERT INTO NLP_Entities (entity_id, entity_text, entity_type) VALUES (1, 'entity1', 'type1');",
      "INSERT INTO NLP_Annotations (annotation_id, document_id, keyword_id, entity_id) VALUES (1, 1, 1, 1);",
      "INSERT INTO NLP_Annotations (annotation_id, entity_id, document_id, keyword_id) VALUES (2, 2, 2, 2);"
    ]
  },
  {
    "statements": [
      "INSERT INTO texts (id, content) VALUES (1, 'Hello, world!');",
      "INSERT INTO tokens (id, text_id, token, position) VALUES (1, 1, 'Hello', 1);",
      "INSERT INTO entities (id, text_id, entity_type, entity_value, start_position, end_position) VALUES (1, 1, 'Greeting', 'Hello', 0, 4);",
      "INSERT INTO relationships (id, text_id, entity1_id, entity2_id, relationship) VALUES (1, 1, 1, 0, 'contains');",
      "INSERT INTO metadata (id, text_id, language, created_at) VALUES (1, 1, 'English', '2022-01-01 00:00:00');",
      "INSERT INTO metadata (id, text_id, language, created_at) VALUES (1, 1, 'English', '2022-05-01 08:00:00');",
      "INSERT INTO tokens (id, text_id, token, position) VALUES (1, 1, 'token1', 1);",
      "INSERT INTO entities (id, text_id, entity_type, entity_value, start_position, end_position) VALUES (1, 1, 'Person', 'John Doe', 5, 12);",
      "INSERT INTO relationships (id, text_id, entity1_id, entity2_id, relationship) VALUES (1, 1, 1, 2, 'related');",
      "INSERT INTO texts (id, content) VALUES (1, 'This is a sample text.');"
    ]
  }
]