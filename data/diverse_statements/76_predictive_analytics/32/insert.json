[
  {
    "statements": [
      "INSERT INTO data_lake (id, file_name, file_type, upload_date, data_size) VALUES (1, 'file1.csv', 'csv', '2022-01-20 08:30:00', 1024);",
      "INSERT INTO data_lake (id, file_name, file_type, upload_date, data_size) VALUES (2, 'file2.xlsx', 'xlsx', '2022-01-21 10:45:00', 2048);",
      "INSERT INTO data_lake (id, file_name, file_type, upload_date, data_size) VALUES (3, 'file3.docx', 'docx', '2022-01-22 12:00:00', 3072);",
      "INSERT INTO data_lake (id, file_name, file_type, upload_date, data_size) VALUES (4, 'file4.txt', 'txt', '2022-01-23 15:20:00', 4096);",
      "INSERT INTO data_lake (id, file_name, file_type, upload_date, data_size) VALUES (5, 'file5.jpg', 'jpg', '2022-01-24 17:45:00', 5120);",
      "INSERT INTO data_lake (id, file_name, file_type, upload_date, data_size) VALUES (1, 'file1.csv', 'csv', '2022-01-01 10:00:00', 5000);",
      "INSERT INTO data_lake (id, file_name, file_type, upload_date, data_size) VALUES (2, 'report.pdf', 'pdf', '2022-02-15 14:30:00', 8000);",
      "INSERT INTO data_lake (data_size, upload_date, file_type, file_name, id) VALUES (3000, '2022-03-20 08:45:00', 'txt', 'textfile.txt', 3);",
      "INSERT INTO data_lake (id, file_name, file_type, data_size, upload_date) VALUES (4, 'spreadsheet.xlsx', 'xlsx', 6000, '2022-04-10 12:00:00');",
      "INSERT INTO data_lake (id, data_size, upload_date, file_type, file_name) VALUES (5, 7000, '2022-05-05 16:20:00', 'zip', 'archive.zip');"
    ]
  },
  {
    "statements": [
      "INSERT INTO DataLake (data_id, file_name, file_type, data_content) VALUES (1, 'file1.txt', 'text', 'Lorem ipsum dolor sit amet');",
      "INSERT INTO DataLake (file_name, data_content, file_type, data_id) VALUES ('file2.csv', 'Data in CSV format', 'csv', 2);",
      "INSERT INTO DataLake (data_id, file_name, data_content, file_type) VALUES (3, 'file3.docx', 'Document file', 'docx');",
      "INSERT INTO DataLake (file_name, file_type, data_content, data_id) VALUES ('file4.jpg', 'image', 'Image file content', 4);",
      "INSERT INTO DataLake (file_name, data_id, file_type, data_content) VALUES ('file5.pdf', 5, 'pdf', 'PDF file content');",
      "INSERT INTO DataLake (data_id, file_name, file_type, data_content) VALUES (1, 'file1.txt', 'text', 'Lorem ipsum dolor sit amet');",
      "INSERT INTO DataTags (tag_id, data_id, tag_name) VALUES (1, 1, 'tag1');",
      "INSERT INTO DataLake (data_id, file_name, file_type, data_content) VALUES (2, 'file2.png', 'image', 'Base64 encoded image data');",
      "INSERT INTO DataTags (tag_id, data_id, tag_name) VALUES (2, 2, 'tag2');",
      "INSERT INTO DataTags (tag_id, data_id, tag_name) VALUES (3, 1, 'tag3');"
    ]
  },
  {
    "statements": [
      "INSERT INTO DataLake (id, file_name, file_size, upload_time) VALUES (1, 'file1.txt', 1024, '2022-01-01 10:00:00')",
      "INSERT INTO Tags (tag_id, tag_name) VALUES (1, 'Important')",
      "INSERT INTO DataTags (id, tag_id) VALUES (1, 1)",
      "INSERT INTO DataLake (id, file_name, file_size, upload_time) VALUES (2, 'file2.csv', 2048, '2022-01-02 12:00:00')",
      "INSERT INTO Tags (tag_id, tag_name) VALUES (2, 'Public')",
      "INSERT INTO DataLake (id, file_name, file_size, upload_time) VALUES (1, 'example_file1.txt', 1024, '2022-01-01 10:00:00');",
      "INSERT INTO Tags (tag_id, tag_name) VALUES (101, 'tag1');",
      "INSERT INTO DataTags (id, tag_id) VALUES (1, 101);",
      "INSERT INTO DataLake (id, file_name, file_size, upload_time) VALUES (2, 'example_file2.txt', 2048, '2022-01-02 12:00:00');",
      "INSERT INTO Tags (tag_id, tag_name) VALUES (102, 'tag2');"
    ]
  },
  {
    "statements": [
      "INSERT INTO data_sources (id, source_name, source_type) VALUES (1, 'Source A', 'Type X');",
      "INSERT INTO data_records (record_id, source_id, record_data, record_date) VALUES (1, 1, '{\"key\": \"value\"}', '2022-01-01 12:00:00');",
      "INSERT INTO data_categories (category_id, category_name) VALUES (1, 'Category 1');",
      "INSERT INTO data_connections (connection_id, source_id, destination_id) VALUES (1, 1, 2);",
      "INSERT INTO data_sources (id, source_name, source_type) VALUES (2, 'Source B', 'Type Y');",
      "INSERT INTO data_sources (id, source_name, source_type) VALUES (1, 'Source A', 'Type A');",
      "INSERT INTO data_records (record_id, source_id, record_data, record_date) VALUES (1, 1, '{\"key\": \"value\"}', '2022-01-01 00:00:00');",
      "INSERT INTO data_categories (category_id, category_name) VALUES (1, 'Category 1');",
      "INSERT INTO data_connections (connection_id, source_id, destination_id) VALUES (1, 1, 2);",
      "INSERT INTO data_sources (id, source_name, source_type) VALUES (2, 'Source B', 'Type B');"
    ]
  },
  {
    "statements": [
      "INSERT INTO data_lake_files (file_id, file_name, file_size, file_type, upload_date) VALUES (1, 'example_file_1.txt', 1024, 'txt', '2022-01-01 12:00:00')",
      "INSERT INTO data_lake_metadata (metadata_id, file_id, metadata_key, metadata_value) VALUES (1, 1, 'description', 'This is an example file')",
      "INSERT INTO data_lake_tags (tag_id, tag_name) VALUES (1, 'important')",
      "INSERT INTO data_lake_file_tags (file_tag_id, file_id, tag_id) VALUES (1, 1, 1)",
      "INSERT INTO data_lake_logs (log_id, action, timestamp, user_id) VALUES (1, 'upload', '2022-01-01 12:00:00', 123)",
      "INSERT INTO data_lake_files (file_id, file_name, file_size, file_type, upload_date) VALUES (1, 'example_file_1.txt', 1024, 'txt', '2022-01-01 12:00:00')",
      "INSERT INTO data_lake_metadata (metadata_id, file_id, metadata_key, metadata_value) VALUES (1, 1, 'description', 'This is an example file')",
      "INSERT INTO data_lake_tags (tag_id, tag_name) VALUES (1, 'important')",
      "INSERT INTO data_lake_file_tags (file_tag_id, file_id, tag_id) VALUES (1, 1, 1)",
      "INSERT INTO data_lake_logs (log_id, action, timestamp, user_id) VALUES (1, 'upload', '2022-01-01 12:00:00', 123)"
    ]
  }
]