[
  {
    "statements": [
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, query, script) VALUES (1, 'Remove Duplicates', 'SELECT DISTINCT * FROM table1', 'python preprocessing_script1.py');",
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, query, script) VALUES (2, 'Handle Missing Values', 'SELECT * FROM table2 WHERE column1 IS NOT NULL', 'python preprocessing_script2.py');",
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, query, script) VALUES (3, 'Normalization', 'UPDATE table3 SET column1 = column1 / 100', 'python preprocessing_script3.py');",
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, query, script) VALUES (4, 'Feature Scaling', 'UPDATE table4 SET column2 = (column2 - mean_value) / std_deviation', 'python preprocessing_script4.py');",
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, query, script) VALUES (5, 'Encoding Categorical Variables', 'UPDATE table5 SET column3 = CASE WHEN column3 = 'Male' THEN 1 ELSE 0 END', 'python preprocessing_script5.py');",
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, query, script) VALUES (1, 'Data Cleaning', 'SELECT * FROM raw_data;', 'python clean_data.py');",
      "INSERT INTO DataPreprocessingTasks (task_name, script, task_id, query) VALUES ('Data Transformation', 'python transform_data.py', 2, 'SELECT * FROM cleaned_data');",
      "INSERT INTO DataPreprocessingTasks (task_id, query, task_name, script) VALUES (3, 'SELECT * FROM transformed_data;', 'Data Analysis', 'python analyze_data.py');",
      "INSERT INTO DataPreprocessingTasks (query, task_id, script, task_name) VALUES ('SELECT * FROM analyzed_data', 4, 'python visualize_data.py', 'Data Visualization');",
      "INSERT INTO DataPreprocessingTasks (task_name, task_id, script, query) VALUES ('Data Modeling', 5, 'python build_model.py', 'SELECT * FROM preprocessed_data');"
    ]
  },
  {
    "statements": [
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, task_description, preprocessing_script) VALUES (1, 'Standardize Data', 'Perform data standardization', 'StandardScaler()');",
      "INSERT INTO FeatureEngineeringTasks (feature_id, feature_name, feature_description, feature_script) VALUES (1, 'Create Polynomial Features', 'Generate polynomial features for regression models', 'PolynomialFeatures()');",
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, task_description, preprocessing_script) VALUES (2, 'Normalize Data', 'Perform data normalization', 'MinMaxScaler()');",
      "INSERT INTO FeatureEngineeringTasks (feature_id, feature_name, feature_description, feature_script) VALUES (2, 'Create Interaction Features', 'Generate interaction features for predictive modeling', 'PolynomialFeatures(interaction_only=True)');",
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, task_description, preprocessing_script) VALUES (3, 'Impute Missing Values', 'Handle missing values in the dataset', 'SimpleImputer(strategy=",
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, task_description, preprocessing_script) VALUES (1, 'Data Cleaning', 'Clean and preprocess data for analysis', 'python clean_data.py');",
      "INSERT INTO FeatureEngineeringTasks (feature_id, feature_name, feature_description, feature_script) VALUES (1, 'Feature Scaling', 'Standardize feature values for modeling', 'python scale_features.py');",
      "INSERT INTO DataPreprocessingTasks (task_id, task_name, task_description, preprocessing_script) VALUES (2, 'Data Transformation', 'Convert data into useful format for analysis', 'python transform_data.py');",
      "INSERT INTO FeatureEngineeringTasks (feature_id, feature_name, feature_description, feature_script) VALUES (2, 'Feature Selection', 'Select important features for modeling', 'python select_features.py');",
      "INSERT INTO FeatureEngineeringTasks (feature_id, feature_name, feature_description, feature_script) VALUES (3, 'Feature Extraction', 'Extract new features from existing data', 'python extract_features.py');"
    ]
  },
  {
    "statements": [
      "INSERT INTO data_preprocessing (column1, column2, column3) VALUES (10, 3.14, 'example');",
      "INSERT INTO feature_engineering (feature_name, feature_value) VALUES ('example feature', 5.0);",
      "INSERT INTO neural_networks (model_name, layers, optimizer) VALUES ('example model', 'Conv2D, Dense', 'Adam');",
      "INSERT INTO feature_engineering (feature_name, feature_value) VALUES ('new feature', 8.25);",
      "INSERT INTO neural_networks (model_name, optimizer, layers) VALUES ('new model', 'SGD', 'Dense, Dropout, Dense');",
      "INSERT INTO data_preprocessing (column1, column2, column3) VALUES (1, 1.5, 'value1');",
      "INSERT INTO feature_engineering (feature_name, feature_value) VALUES ('feature1', 2.5);",
      "INSERT INTO neural_networks (model_name, layers, optimizer) VALUES ('model1', 'layer1, layer2, layer3', 'adam');",
      "INSERT INTO data_preprocessing (column1, column2, column3) VALUES (2, 3.2, 'value2');",
      "INSERT INTO feature_engineering (feature_name, feature_value) VALUES ('feature2', 4.7);"
    ]
  },
  {
    "statements": [
      "INSERT INTO data_preprocessing (id, data, target, preprocessing_script) VALUES ('123e4567-e89b-12d3-a456-426614174000', 'raw_data_1', 'target_1', 'script_1');",
      "INSERT INTO feature_engineering (id, data_preprocessed, feature_vector, engineering_script) VALUES ('223e4567-e89b-12d3-a456-426614174000', 'preprocessed_data_1', 'feature_vector_1', 'engineer_script_1');",
      "INSERT INTO neural_network (id, feature_input, labels, model_script) VALUES ('323e4567-e89b-12d3-a456-426614174000', 'input_features_1', 'labels_1', 'model_script_1');",
      "INSERT INTO training_data (id, feature_input_transformed, labels_transformed, hyperparameters) VALUES ('423e4567-e89b-12d3-a456-426614174000', 'transformed_input_1', 'transformed_labels_1', 'hyperparameters_1');",
      "INSERT INTO data_preprocessing (id, data, target, preprocessing_script) VALUES ('523e4567-e89b-12d3-a456-426614174000', 'raw_data_2', 'target_2', 'script_2');",
      "INSERT INTO data_preprocessing (id, data, target, preprocessing_script) VALUES ('c7ea9049-1958-4f9c-b69a-41bebed5452c', 'data1', 'target1', 'script1');",
      "INSERT INTO training_data (id, feature_input_transformed, labels_transformed, hyperparameters) VALUES ('b8b52561-1484-4c94-8587-ea8d36c2d3d3', 'input1', 'labels1', 'hyperparams1');",
      "INSERT INTO feature_engineering (id, data_preprocessed, feature_vector, engineering_script) VALUES ('fc58f624-f52e-441f-843f-2f9a0d9435da', 'preprocessed_data1', 'vector1', 'engineering_script1');",
      "INSERT INTO neural_network (id, feature_input, labels, model_script) VALUES ('4f257ca4-a29a-403d-a0a7-e7242c71b362', 'input_features1', 'labels1', 'model_script1');",
      "INSERT INTO training_data (id, feature_input_transformed, labels_transformed, hyperparameters) VALUES ('724f0574-97ef-47aa-97b7-bd1f41ffe55c', 'input2', 'labels2', 'hyperparams2');"
    ]
  },
  {
    "statements": [
      "INSERT INTO Data_Preprocessing (id, data_input, data_output, preprocessing_script) VALUES (1, 'input_data_1', 'output_data_1', 'script_1');",
      "INSERT INTO Evaluation_Metrics (id, metric_name, metric_value) VALUES (1, 'accuracy', 0.85);",
      "INSERT INTO Feature_Engineering (id, input_feature, output_feature, engineering_script) VALUES (1, 'feature_1', 'engineered_feature_1', 'engineering_script_1');",
      "INSERT INTO Neural_Network_Model (id, model_name, model_architecture, model_parameters) VALUES (1, 'model_1', 'architecture_1', 'parameters_1');",
      "INSERT INTO Training_Data (id, data_input, data_output, training_script) VALUES (1, 'train_data_1', 'output_data_1', 'training_script_1');",
      "INSERT INTO Data_Preprocessing (id, data_input, data_output, preprocessing_script) VALUES (1, 'input_data_1', 'output_data_1', 'preprocess_script_1');",
      "INSERT INTO Feature_Engineering (id, input_feature, output_feature, engineering_script) VALUES (1, 'feature_1', 'new_feature_1', 'engineering_script_1');",
      "INSERT INTO Neural_Network_Model (id, model_name, model_architecture, model_parameters) VALUES (1, 'model_1', 'architecture_1', 'parameters_1');",
      "INSERT INTO Training_Data (id, data_input, data_output, training_script) VALUES (1, 'input_data_1', 'output_data_1', 'training_script_1');",
      "INSERT INTO Evaluation_Metrics (id, metric_name, metric_value) VALUES (1, 'metric_1', 0.75);"
    ]
  }
]