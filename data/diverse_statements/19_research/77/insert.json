[
  {
    "statements": [
      "INSERT INTO research_data (id, source, data_text, data_date) VALUES (1, 'Source A', 'Text A', '2022-01-01');",
      "INSERT INTO research_data (source, data_text, data_date, id) VALUES ('Source B', 'Text B', '2022-02-02', 2);",
      "INSERT INTO research_data (data_date, source, data_text, id) VALUES ('2022-03-03', 'Source C', 'Text C', 3);",
      "INSERT INTO research_data (data_text, id, data_date, source) VALUES ('Text D', 4, '2022-04-04', 'Source D');",
      "INSERT INTO research_data (source, id, data_date, data_text) VALUES ('Source E', 5, '2022-05-05', 'Text E');",
      "INSERT INTO research_data (id, source, data_text, data_date) VALUES (1, 'Journal A', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla sit amet arcu in mauris convallis bibendum nec et libero.', '2022-01-10');",
      "INSERT INTO research_data (source, data_text, data_date, id) VALUES ('Database XYZ', 'Sed lobortis diam eget libero eleifend, quis ultricies lacus efficitur. Duis sed feugiat nulla.', '2022-02-15', 2);",
      "INSERT INTO research_data (data_date, data_text, source, id) VALUES ('2022-03-20', 'Vestibulum sit amet est aliquam, scelerisque lacus a, tempus elit. Aenean fermentum ullamcorper velit.', 'Journal B', 3);",
      "INSERT INTO research_data (id, data_text, source, data_date) VALUES (4, 'Ut lacinia sem eu odio consequat, ut fermentum mi tincidunt. Sed molestie, leo sit amet ultricies vehicula.', 'Conference ABC', '2022-04-25');",
      "INSERT INTO research_data (data_text, source, data_date, id) VALUES ('Nunc auctor odio nec mauris euismod, at fringilla nulla tristique. Proin accumsan, quam sed rutrum.', 'Journal C', '2022-05-30', 5);"
    ]
  },
  {
    "statements": [
      "INSERT INTO DatasetCleaning(dataset_id, dataset_name, data_source, cleaning_method, cleaned_data) VALUES('1a9c4871-4241-4e24-b8da-202c68bd8bdf', 'SalesData', 'CSV', 'RemoveDuplicates', '{\"date\": \"2023-01-15\", \"sales_amount\": 15000}')",
      "INSERT INTO StatisticalAnalysis(analysis_id, dataset_id, analysis_type, analysis_result) VALUES('c72dc22d-b423-4bd9-9fe2-8a6037d58a0a', '1a9c4871-4241-4e24-b8da-202c68bd8bdf', 'Regression', '{\"R-squared\": 0.87}')",
      "INSERT INTO DatasetCleaning(dataset_id, dataset_name, data_source, cleaning_method, cleaned_data) VALUES('f38baefa-8770-473a-bc6a-53d5b76d6df5', 'CustomerData', 'Excel', 'RemoveNullValues', '{\"customer_id\": 12345, \"customer_name\": \"John Doe\"}')",
      "INSERT INTO StatisticalAnalysis(analysis_id, dataset_id, analysis_type, analysis_result) VALUES('cb1ba33e-c773-4b45-b521-6488f786a1df', 'f38baefa-8770-473a-bc6a-53d5b76d6df5', 'Classification', '{\"Accuracy\": 0.92}')",
      "INSERT INTO DatasetCleaning(dataset_id, dataset_name, data_source, cleaning_method, cleaned_data) VALUES('e9a3b65d-8796-4a4a-9d36-5fc0d30912b1', 'ProductCatalog', 'API', 'RemoveDuplicates', '{\"product_id\": 98765, \"product_name\": \"Smartphone\"}')",
      "INSERT INTO DatasetCleaning (dataset_id, dataset_name, data_source, cleaning_method, cleaned_data) VALUES ('84a35c9a-4502-4e7e-839d-2af58e33017c', 'SalesData', 'CSV', 'Regex Cleaning', '{\"sales\": [100, 200, 150]}');",
      "INSERT INTO StatisticalAnalysis (analysis_id, dataset_id, analysis_type, analysis_result) VALUES ('784e5b3d-5eeb-4fa4-97d7-2f95e55bef94', '84a35c9a-4502-4e7e-839d-2af58e33017c', 'Regression Analysis', '{\"coefficients\": [0.5, 0.8]}');",
      "INSERT INTO DatasetCleaning (dataset_name, data_source, cleaning_method, dataset_id, cleaned_data) VALUES ('CustomerData', 'JSON', 'Null Value Handling', '317176f0-52da-4fe9-b4e1-5f0fb36562d3', '{\"customers\": [\"John\", \"Alice\", \"Bob\"]}');",
      "INSERT INTO StatisticalAnalysis (dataset_id, analysis_type, analysis_result, analysis_id) VALUES ('84a35c9a-4502-4e7e-839d-2af58e33017c', 'Descriptive Statistics', '{\"mean\": 50, \"median\": 45}', '8e6f8ea8-b074-41f5-8a45-82b9f2ccbd14');",
      "INSERT INTO DatasetCleaning (dataset_name, data_source, cleaning_method, dataset_id, cleaned_data) VALUES ('InventoryData', 'Excel', 'Outlier Detection', '19db7566-7e51-4e07-9b8a-5d713eeb3706', '{\"items\": [\"Item1\", \"Item2\", \"Item3\"]}');"
    ]
  },
  {
    "statements": [
      "INSERT INTO DataCleaning (id, dataset_id, cleaning_steps, cleaned_data, cleaning_status) VALUES (1, 101, 'Remove duplicates', '{\"columns\": [\"A\", \"B\", \"C\"]}', TRUE);",
      "INSERT INTO Preprocessing (id, dataset_id, preprocessing_steps, preprocessed_data, processing_status) VALUES (1, 201, 'Normalization', '{\"mean\": 0, \"std_dev\": 1}', FALSE);",
      "INSERT INTO StatisticalAnalysis (id, dataset_id, analysis_steps, analysis_results) VALUES (1, 301, 'Hypothesis Testing', '{\"p_value\": 0.05, \"confidence_interval\": [0.9, 0.95]}');",
      "INSERT INTO DataCleaning (id, dataset_id, cleaning_steps, cleaned_data, cleaning_status) VALUES (2, 102, 'Fill missing values', '{\"method\": \"mean\"}', FALSE);",
      "INSERT INTO Preprocessing (id, dataset_id, preprocessing_steps, preprocessed_data, processing_status) VALUES (2, 202, 'Standardization', '{\"mean\": 10, \"std_dev\": 2}', TRUE);",
      "INSERT INTO DataCleaning (id, dataset_id, cleaning_steps, cleaned_data, cleaning_status) VALUES (1, 101, 'Remove duplicates', '{\"column1\": [1, 2, 3], \"column2\": [\"a\", \"b\", \"c\"]}', TRUE);",
      "INSERT INTO StatisticalAnalysis (id, dataset_id, analysis_steps, analysis_results) VALUES (1, 101, 'Descriptive Statistics', '{\"mean\": 50, \"median\": 45, \"std_dev\": 12}');",
      "INSERT INTO DataCleaning (id, cleaning_steps, dataset_id, cleaned_data, cleaning_status) VALUES (2, 'Remove outliers', 102, '{\"column1\": [5, 6, 7], \"column2\": [\"x\", \"y\", \"z\"]}', FALSE);",
      "INSERT INTO Preprocessing (dataset_id, id, preprocessing_steps, preprocessed_data, processing_status) VALUES (103, 3, 'Feature Scaling', '{\"column1\": [0.5, 0.6, 0.7], \"column2\": [\"M\", \"F\", \"M\"]}', TRUE);",
      "INSERT INTO StatisticalAnalysis (analysis_steps, id, dataset_id, analysis_results) VALUES ('Correlation Analysis', 2, 102, '{\"correlation\": 0.85}');"
    ]
  },
  {
    "statements": [
      "INSERT INTO Studies (study_id, study_name, research_field, dataset_location) VALUES ('1b9d6bcd-bbfd-4b2d-9b5d-ab8dfbbd4bf6', 'Study A', 'Biology', 's3://data/studyA')",
      "INSERT INTO Researchers (researcher_id, researcher_name, institution, email) VALUES ('9b6e1d4d-7e0b-4522-9303-972629bb8d0d', 'John Doe', 'University of Science', 'john.doe@example.com')",
      "INSERT INTO Datasets (dataset_id, dataset_name, source, size_bytes, creation_date) VALUES ('e692e12d-0f46-4dcd-8b53-4b724e7d0ed7', 'Data Set X', 'External Source', 2048, '2022-03-15 10:30:00')",
      "INSERT INTO PreprocessedData (data_id, dataset_id, preprocessing_steps, cleaned_data_location) VALUES ('48368227-2173-4b3a-b2b4-b146a075a557', 'e692e12d-0f46-4dcd-8b53-4b724e7d0ed7', 'Normalization, Feature Selection', 's3://data/preprocessed_datasetX')",
      "INSERT INTO Researchers (researcher_id, researcher_name, institution, email) VALUES ('c8a3c189-d3a1-48b4-9861-6659e9f67db8', 'Jane Smith', 'Research Institute', 'jane.smith@example.com')",
      "INSERT INTO Studies (study_id, study_name, research_field, dataset_location) VALUES ('1a2b3c4d-5e6f-7g8h-9i0j', 'Study A', 'Biology', 'S3://studyA/data')",
      "INSERT INTO Researchers (researcher_id, researcher_name, institution, email) VALUES ('9i8h7g-6f5e-4d3c-2b1a', 'John Doe', 'University X', 'john.doe@example.com')",
      "INSERT INTO Datasets (dataset_id, dataset_name, source, size_bytes, creation_date) VALUES ('a1b2c3d4-5e6f-7g8h-9i0j', 'Dataset X', 'Research Lab', 1024, '2022-01-15 12:00:00')",
      "INSERT INTO PreprocessedData (data_id, dataset_id, preprocessing_steps, cleaned_data_location) VALUES ('4d3c2b1a-5e6f-7g8h-9i0j', 'a1b2c3d4-5e6f-7g8h-9i0j', 'Normalization, Feature Engineering', 'S3://preprocessed/dataX')",
      "INSERT INTO Studies (study_id, study_name, research_field, dataset_location) VALUES ('0j9i8h7g-6f5e-4d3c-2b1a', 'Study B', 'Computer Science', 'S3://studyB/data')"
    ]
  },
  {
    "statements": [
      "INSERT INTO Researchers (researcher_id, name, institution) VALUES (1, 'Alice Smith', 'University of ABC');",
      "INSERT INTO Datasets (dataset_id, name, source) VALUES (101, 'Data Set A', 'Source X');",
      "INSERT INTO CleaningSteps (step_id, step_name, description) VALUES (1, 'Data Cleaning', 'Remove duplicates and missing values');",
      "INSERT INTO PreprocessingSteps (preprocess_id, preprocess_name, action) VALUES (101, 'Data Normalization', 'Scale data to [0,1] range');",
      "INSERT INTO StatisticalAnalysis (analysis_id, analysis_name, technique) VALUES (1, 'Regression Analysis', 'Linear Regression');",
      "INSERT INTO Researchers (researcher_id, name, institution) VALUES (1, 'John Doe', 'University A');",
      "INSERT INTO Datasets (dataset_id, name, source) VALUES (1, 'Dataset X', 'Source A');",
      "INSERT INTO CleaningSteps (step_id, step_name, description) VALUES (1, 'Step 1', 'Remove outliers and missing values');",
      "INSERT INTO PreprocessingSteps (preprocess_id, preprocess_name, action) VALUES (1, 'Normalization', 'Scale data between 0 and 1');",
      "INSERT INTO StatisticalAnalysis (analysis_id, analysis_name, technique) VALUES (1, 'Regression Analysis', 'Linear Regression');"
    ]
  }
]